{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn-mnist-rng.ipynb","provenance":[{"file_id":"1g62-drW3DgUzp_u7gPzCCi2v_L30uDyn","timestamp":1584540792517},{"file_id":"1pAR6bAtvt3JEkk5VruDhCLwnmasm3Daj","timestamp":1582622493209}],"collapsed_sections":[],"authorship_tag":"ABX9TyMh30yW0D3hG+YODfj/XsOq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ew4CTxbeVe5S","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TRaHKezWswn","colab_type":"text"},"source":["#Deep Learning Project (CNN with fractional_max for MNIST)\n","---\n","###Running the Experiment on Google Colab\n","This notebook is running remotely on the Google Colab Platform, therefore to save and access the trained model and checkpoints in your local computer you need to mount the Google Drive. Specify the path to your project directory.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"JsO7YS3zTkTD","colab_type":"code","outputId":"8651922d-9c72-4acb-e424-7b869849afaf","executionInfo":{"status":"ok","timestamp":1584973200574,"user_tz":-60,"elapsed":35670,"user":{"displayName":"Cheng Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4TVdjKYmvrWfS8ohWbTwpZoi9RbJJAdrt06yNFw=s64","userId":"06476187500193724514"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')\n","!ls '/content/gdrive/My Drive/'\n","path = '/content/gdrive/My Drive/CS4240_Project/' #set the path as your own location\n","os.chdir(path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","Archive  CS4240_Project  D2L  RQ\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BTz93Nf0c-1J","colab_type":"text"},"source":["###Import Required Libraries and Datasets"]},{"cell_type":"code","metadata":{"id":"ER-AdS4OYLnu","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torchvision import transforms\n","import matplotlib\n","from matplotlib import pyplot as plt\n","import datetime\n","from torchsummary import summary\n","import numpy as np\n","%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E349STMwdS2Y","colab_type":"text"},"source":["Download the MNIST dataset using `torchvision.datasets`.\n","\n"]},{"cell_type":"code","metadata":{"id":"owZYZZvmXnQH","colab_type":"code","outputId":"fdbaddb4-40e8-4bfe-fe2d-384fe4a7b53a","executionInfo":{"status":"ok","timestamp":1584973207254,"user_tz":-60,"elapsed":42337,"user":{"displayName":"Cheng Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4TVdjKYmvrWfS8ohWbTwpZoi9RbJJAdrt06yNFw=s64","userId":"06476187500193724514"}},"colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["data_path = path + 'data/'\n","save_path = path + 'model/'\n","MNIST_train = datasets.MNIST(data_path, train = True, download = False, transform = transforms.ToTensor())\n","MNIST_test = datasets.MNIST(data_path, train = False, download = False, transform = transforms.ToTensor())\n","img, _ = MNIST_train[5]\n","print(img.shape)\n","plt.imshow(img[0])\n","print('class:', _)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n","class: 2\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2IEg/h8CIWRCsmbzCQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"6wDmtBLRqzfe","colab_type":"text"},"source":["Use `torch.utils.data.DataLoader` to assign batch and apply shuffle to data.\n"]},{"cell_type":"code","metadata":{"id":"pj97pqdCivtA","colab_type":"code","colab":{}},"source":["#load data as batches\n","train_loader = torch.utils.data.DataLoader(MNIST_train,\n","                                            batch_size = 64,\n","                                            shuffle = True)\n","val_loader = torch.utils.data.DataLoader(MNIST_test,\n","                                            batch_size = 64,\n","                                            shuffle = False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3swjcnVrjmzR","colab_type":"text"},"source":["###Build the Convolutional Neural Network\n"]},{"cell_type":"markdown","metadata":{"id":"ZMzgm1EROe-O","colab_type":"text"},"source":["Fractional MaxPooling 6 layers:"]},{"cell_type":"code","metadata":{"id":"CYnL-7WtOard","colab_type":"code","outputId":"28b5116f-4c26-4eb5-edc9-d539668c909f","executionInfo":{"status":"ok","timestamp":1584973217560,"user_tz":-60,"elapsed":52632,"user":{"displayName":"Cheng Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4TVdjKYmvrWfS8ohWbTwpZoi9RbJJAdrt06yNFw=s64","userId":"06476187500193724514"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["class Net_Fmax(nn.Module):\n","  def __init__(self):\n","    super(Net_Fmax, self).__init__()\n","    self.conv1 = nn.Conv2d(1,   32,  kernel_size=2, padding=4)\n","    self.conv2 = nn.Conv2d(32,  64,  kernel_size=2, padding=0)\n","    self.conv3 = nn.Conv2d(64,  96,  kernel_size=2, padding=0)\n","    self.conv4 = nn.Conv2d(96,  128, kernel_size=2, padding=0)\n","    self.conv5 = nn.Conv2d(128, 160, kernel_size=2, padding=0)\n","    self.conv6 = nn.Conv2d(160, 192, kernel_size=2, padding=0)\n","    self.conv7 = nn.Conv2d(192, 192, kernel_size=2, padding=0)\n","    self.frac_maxpool = nn.FractionalMaxPool2d(kernel_size = 2, output_ratio = (0.72,0.72))\n","    self.fc = nn.Linear(192, 10)\n","\n","  def forward(self, x):\n","    out = F.relu(self.frac_maxpool(self.conv1(x)))\n","    out = F.relu(self.frac_maxpool(self.conv2(out)))\n","    out = F.relu(self.frac_maxpool(self.conv3(out)))\n","    out = F.relu(self.frac_maxpool(self.conv4(out)))\n","    out = F.relu(self.frac_maxpool(self.conv5(out)))\n","    out = F.relu(self.frac_maxpool(self.conv6(out)))\n","    out = F.relu(self.conv7(out))\n","    out = out.view(-1, 192)\n","    out = self.fc(out)\n","    return out\n","summary(Net_Fmax().cuda(), (1,28,28))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 35, 35]             160\n","FractionalMaxPool2d-2           [-1, 32, 25, 25]               0\n","            Conv2d-3           [-1, 64, 24, 24]           8,256\n","FractionalMaxPool2d-4           [-1, 64, 17, 17]               0\n","            Conv2d-5           [-1, 96, 16, 16]          24,672\n","FractionalMaxPool2d-6           [-1, 96, 11, 11]               0\n","            Conv2d-7          [-1, 128, 10, 10]          49,280\n","FractionalMaxPool2d-8            [-1, 128, 7, 7]               0\n","            Conv2d-9            [-1, 160, 6, 6]          82,080\n","FractionalMaxPool2d-10            [-1, 160, 4, 4]               0\n","           Conv2d-11            [-1, 192, 3, 3]         123,072\n","FractionalMaxPool2d-12            [-1, 192, 2, 2]               0\n","           Conv2d-13            [-1, 192, 1, 1]         147,648\n","           Linear-14                   [-1, 10]           1,930\n","================================================================\n","Total params: 437,098\n","Trainable params: 437,098\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.38\n","Params size (MB): 1.67\n","Estimated Total Size (MB): 3.05\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_BHbHG0-kBKm","colab_type":"text"},"source":["###Design Training Loop"]},{"cell_type":"code","metadata":{"id":"JpC9SmJYj31q","colab_type":"code","outputId":"8b07fa88-e3d2-4019-e403-a49b7574a9e0","executionInfo":{"status":"ok","timestamp":1584973222712,"user_tz":-60,"elapsed":57775,"user":{"displayName":"Cheng Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4TVdjKYmvrWfS8ohWbTwpZoi9RbJJAdrt06yNFw=s64","userId":"06476187500193724514"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter('./runs_Fmax')\n","\n","def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n","    max_accuracy = 0\n","    for epoch in range(1, n_epochs + 1):\n","        loss_train = 0.0\n","        for imgs, labels in train_loader:\n","          outputs = model(imgs.cuda())\n","          labels = labels.cuda()\n","          loss = loss_fn(outputs, labels)\n","          optimizer.zero_grad() #for gradient accumulation\n","          loss.backward()\n","          optimizer.step()\n","          loss_train += loss.item() #for visualization \n","          writer.add_scalar('train_loss', loss.item(), epoch)\n","        \n","        #tensorboard write, for every 10 epochs, print train loss\n","        if epoch == 1 or epoch % 15 == 0:\n","            with torch.no_grad():\n","              total = 0\n","              correct = 0\n","\n","              for imgs_val, labels_val in val_loader:\n","                imgs_val = imgs_val.cuda()\n","                labels_val = labels_val.cuda()\n","                outputs_val = model.eval()(imgs_val)\n","                _, index_max = torch.max(outputs_val, dim = 1)\n","                total += labels_val.shape[0]  #val_loader has no attribute shape\n","                correct += (index_max == labels_val).sum().item()\n","              accuracy = float(correct / total)\n","\n","              if accuracy >= max_accuracy:\n","                max_accuracy = accuracy\n","\n","            print('{} Epoch {:3}, Training Loss {:2.6f}, Max Test Accuracy {:2.6f}'.format(datetime.datetime.now(), epoch, float(loss_train), float(max_accuracy)))\n","            writer.add_scalar('test_accuracy', accuracy, epoch)\n","\n","    print('Finished Training')\n","    writer.close()\n","    return max_accuracy"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"grt7JAqX4zmf","colab_type":"text"},"source":["###Run optimization (SGD Momentum) \n","To use **GPU** acceleration, we need to make sure our model is running in GPU mode, which only accept `torch.cuda.FloatTensor` as inputs."]},{"cell_type":"code","metadata":{"id":"zu05ees-5viU","colab_type":"code","outputId":"83a65aa7-26c7-4fe2-bd91-5b7dcc4ed56a","executionInfo":{"status":"ok","timestamp":1584973222712,"user_tz":-60,"elapsed":57767,"user":{"displayName":"Cheng Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4TVdjKYmvrWfS8ohWbTwpZoi9RbJJAdrt06yNFw=s64","userId":"06476187500193724514"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","print('CUDA is available:', torch.cuda.is_available())\n","learning_rate = 1e-2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CUDA is available: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tEEnRZICIGPB","colab_type":"text"},"source":["Set up random number generator (RNG)"]},{"cell_type":"code","metadata":{"id":"eq0XgzcHH94D","colab_type":"code","colab":{}},"source":["def setup_seed(seed):\n","     torch.manual_seed(seed)\n","     torch.cuda.manual_seed_all(seed)\n","     np.random.seed(seed)\n","     torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fzdYFlKwkT11","colab_type":"text"},"source":["Remember `NLLLoss = -sum(log(output_i[c_i])` where the `sum` is taken over $n$ samples and $c_i$ is the correct class for sample $i$."]},{"cell_type":"code","metadata":{"id":"v3IslElFkaaV","colab_type":"code","outputId":"37ff6154-f2ae-43ca-8bde-11a47412cbd7","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["number_of_tests = 4\n","max_accuracy = [] #12 trainings and tests\n","for seed in range(number_of_tests):\n","  setup_seed(1)\n","  model = Net_Fmax().cuda()\n","  optimizer = optim.SGD(params = model.parameters(), lr = learning_rate, momentum = 0.9)  #be careful with the calculation chain!\n","  test_accuracy = training_loop(n_epochs = 2000,\n","                        optimizer = optimizer,\n","                        model = model.train(),\n","                        loss_fn = nn.CrossEntropyLoss(),  #equivalent to LogSoftmax & NLLLoss\n","                        train_loader = train_loader)\n","  max_accuracy.append(test_accuracy)\n","  print(\"Best test accuracy:\\n\", max_accuracy)  #Expect: 0.34 test error"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-23 14:20:54.146808 Epoch   1, Training Loss 2016.909211, Max Test Accuracy 0.756000\n","2020-03-23 14:23:32.634577 Epoch  15, Training Loss 21.432168, Max Test Accuracy 0.991600\n","2020-03-23 14:26:22.112137 Epoch  30, Training Loss 10.156166, Max Test Accuracy 0.992500\n","2020-03-23 14:29:11.763951 Epoch  45, Training Loss 7.539145, Max Test Accuracy 0.994200\n","2020-03-23 14:32:03.271766 Epoch  60, Training Loss 5.632886, Max Test Accuracy 0.994700\n","2020-03-23 14:34:54.912676 Epoch  75, Training Loss 3.174332, Max Test Accuracy 0.994700\n","2020-03-23 14:37:46.061911 Epoch  90, Training Loss 2.682190, Max Test Accuracy 0.994700\n","2020-03-23 14:40:37.318198 Epoch 105, Training Loss 1.929618, Max Test Accuracy 0.994700\n","2020-03-23 14:43:28.316905 Epoch 120, Training Loss 3.508312, Max Test Accuracy 0.994700\n","2020-03-23 14:46:18.919544 Epoch 135, Training Loss 1.687135, Max Test Accuracy 0.994700\n","2020-03-23 14:49:12.358630 Epoch 150, Training Loss 1.719820, Max Test Accuracy 0.994700\n","2020-03-23 14:52:03.725967 Epoch 165, Training Loss 1.327241, Max Test Accuracy 0.995800\n","2020-03-23 14:54:54.359682 Epoch 180, Training Loss 0.860317, Max Test Accuracy 0.995800\n","2020-03-23 14:57:45.010231 Epoch 195, Training Loss 1.267246, Max Test Accuracy 0.995800\n","2020-03-23 15:00:35.143443 Epoch 210, Training Loss 1.398028, Max Test Accuracy 0.995800\n","2020-03-23 15:03:25.477341 Epoch 225, Training Loss 1.429210, Max Test Accuracy 0.995800\n","2020-03-23 15:06:15.513018 Epoch 240, Training Loss 0.774616, Max Test Accuracy 0.995800\n","2020-03-23 15:09:04.059024 Epoch 255, Training Loss 1.101188, Max Test Accuracy 0.995800\n","2020-03-23 15:11:50.937921 Epoch 270, Training Loss 0.451846, Max Test Accuracy 0.995800\n","2020-03-23 15:14:38.666214 Epoch 285, Training Loss 1.008789, Max Test Accuracy 0.995800\n","2020-03-23 15:17:28.810585 Epoch 300, Training Loss 0.511504, Max Test Accuracy 0.995800\n","2020-03-23 15:20:21.033346 Epoch 315, Training Loss 0.689348, Max Test Accuracy 0.995800\n","2020-03-23 15:23:09.797156 Epoch 330, Training Loss 1.102953, Max Test Accuracy 0.995800\n","2020-03-23 15:25:57.731383 Epoch 345, Training Loss 0.217643, Max Test Accuracy 0.995800\n","2020-03-23 15:28:46.247243 Epoch 360, Training Loss 0.823652, Max Test Accuracy 0.995800\n","2020-03-23 15:31:34.231673 Epoch 375, Training Loss 0.542735, Max Test Accuracy 0.995800\n","2020-03-23 15:34:21.541378 Epoch 390, Training Loss 0.490594, Max Test Accuracy 0.995800\n","2020-03-23 15:37:06.672625 Epoch 405, Training Loss 0.141270, Max Test Accuracy 0.995800\n","2020-03-23 15:39:50.787335 Epoch 420, Training Loss 0.401687, Max Test Accuracy 0.995800\n","2020-03-23 15:42:34.214930 Epoch 435, Training Loss 0.718484, Max Test Accuracy 0.995800\n","2020-03-23 15:45:16.725951 Epoch 450, Training Loss 0.559181, Max Test Accuracy 0.995800\n","2020-03-23 15:48:00.235931 Epoch 465, Training Loss 0.597297, Max Test Accuracy 0.995800\n","2020-03-23 15:50:42.809797 Epoch 480, Training Loss 0.894702, Max Test Accuracy 0.995800\n","2020-03-23 15:53:24.548487 Epoch 495, Training Loss 1.421378, Max Test Accuracy 0.995800\n","2020-03-23 15:56:06.028272 Epoch 510, Training Loss 0.280978, Max Test Accuracy 0.995800\n","2020-03-23 15:58:47.613271 Epoch 525, Training Loss 0.251022, Max Test Accuracy 0.995800\n","2020-03-23 16:01:28.909995 Epoch 540, Training Loss 0.390817, Max Test Accuracy 0.995800\n","2020-03-23 16:04:10.390033 Epoch 555, Training Loss 0.288151, Max Test Accuracy 0.995800\n","2020-03-23 16:06:51.633836 Epoch 570, Training Loss 0.480556, Max Test Accuracy 0.995800\n","2020-03-23 16:09:33.086621 Epoch 585, Training Loss 0.731797, Max Test Accuracy 0.995800\n","2020-03-23 16:12:17.671507 Epoch 600, Training Loss 0.146062, Max Test Accuracy 0.995800\n","2020-03-23 16:14:59.925869 Epoch 615, Training Loss 0.382613, Max Test Accuracy 0.995900\n","2020-03-23 16:17:41.129579 Epoch 630, Training Loss 0.355629, Max Test Accuracy 0.995900\n","2020-03-23 16:20:23.022014 Epoch 645, Training Loss 0.057600, Max Test Accuracy 0.995900\n","2020-03-23 16:23:04.761001 Epoch 660, Training Loss 0.427239, Max Test Accuracy 0.995900\n","2020-03-23 16:25:45.878383 Epoch 675, Training Loss 0.716525, Max Test Accuracy 0.995900\n","2020-03-23 16:28:27.703226 Epoch 690, Training Loss 0.581198, Max Test Accuracy 0.995900\n","2020-03-23 16:31:08.832142 Epoch 705, Training Loss 0.172419, Max Test Accuracy 0.995900\n","2020-03-23 16:33:50.244745 Epoch 720, Training Loss 0.165959, Max Test Accuracy 0.995900\n","2020-03-23 16:36:31.319943 Epoch 735, Training Loss 0.298358, Max Test Accuracy 0.995900\n","2020-03-23 16:39:12.128431 Epoch 750, Training Loss 0.449779, Max Test Accuracy 0.995900\n","2020-03-23 16:41:52.662830 Epoch 765, Training Loss 0.562987, Max Test Accuracy 0.995900\n","2020-03-23 16:44:33.605231 Epoch 780, Training Loss 0.102064, Max Test Accuracy 0.995900\n","2020-03-23 16:47:15.415803 Epoch 795, Training Loss 0.339339, Max Test Accuracy 0.995900\n","2020-03-23 16:49:57.350120 Epoch 810, Training Loss 0.486330, Max Test Accuracy 0.995900\n","2020-03-23 16:52:38.035483 Epoch 825, Training Loss 0.572613, Max Test Accuracy 0.995900\n","2020-03-23 16:55:19.048544 Epoch 840, Training Loss 0.288674, Max Test Accuracy 0.995900\n","2020-03-23 16:58:00.052222 Epoch 855, Training Loss 0.121998, Max Test Accuracy 0.995900\n","2020-03-23 17:00:40.953905 Epoch 870, Training Loss 0.013950, Max Test Accuracy 0.995900\n","2020-03-23 17:03:21.391003 Epoch 885, Training Loss 0.086657, Max Test Accuracy 0.995900\n","2020-03-23 17:06:02.407213 Epoch 900, Training Loss 0.874048, Max Test Accuracy 0.995900\n","2020-03-23 17:08:43.088017 Epoch 915, Training Loss 0.247236, Max Test Accuracy 0.995900\n","2020-03-23 17:11:23.988311 Epoch 930, Training Loss 0.309846, Max Test Accuracy 0.995900\n","2020-03-23 17:14:05.563431 Epoch 945, Training Loss 0.146824, Max Test Accuracy 0.995900\n","2020-03-23 17:16:48.244480 Epoch 960, Training Loss 0.338446, Max Test Accuracy 0.995900\n","2020-03-23 17:19:36.232616 Epoch 975, Training Loss 0.441592, Max Test Accuracy 0.995900\n","2020-03-23 17:22:25.984316 Epoch 990, Training Loss 0.232513, Max Test Accuracy 0.995900\n","2020-03-23 17:25:15.260513 Epoch 1005, Training Loss 0.498047, Max Test Accuracy 0.995900\n","2020-03-23 17:28:05.777403 Epoch 1020, Training Loss 0.122522, Max Test Accuracy 0.995900\n","2020-03-23 17:30:55.790114 Epoch 1035, Training Loss 0.121366, Max Test Accuracy 0.995900\n","2020-03-23 17:33:43.591260 Epoch 1050, Training Loss 0.173779, Max Test Accuracy 0.995900\n","2020-03-23 17:36:29.205375 Epoch 1065, Training Loss 0.674245, Max Test Accuracy 0.995900\n","2020-03-23 17:39:12.588093 Epoch 1080, Training Loss 0.193937, Max Test Accuracy 0.995900\n","2020-03-23 17:41:55.534240 Epoch 1095, Training Loss 0.156638, Max Test Accuracy 0.995900\n","2020-03-23 17:44:37.837609 Epoch 1110, Training Loss 0.441902, Max Test Accuracy 0.995900\n","2020-03-23 17:47:20.988211 Epoch 1125, Training Loss 0.035129, Max Test Accuracy 0.995900\n","2020-03-23 17:50:03.956902 Epoch 1140, Training Loss 0.404079, Max Test Accuracy 0.995900\n","2020-03-23 17:52:46.164781 Epoch 1155, Training Loss 0.484969, Max Test Accuracy 0.995900\n","2020-03-23 17:55:28.775464 Epoch 1170, Training Loss 0.026114, Max Test Accuracy 0.995900\n","2020-03-23 17:58:10.629241 Epoch 1185, Training Loss 0.039114, Max Test Accuracy 0.995900\n","2020-03-23 18:00:52.137595 Epoch 1200, Training Loss 0.285823, Max Test Accuracy 0.995900\n","2020-03-23 18:03:33.602916 Epoch 1215, Training Loss 0.234009, Max Test Accuracy 0.996200\n","2020-03-23 18:06:14.998723 Epoch 1230, Training Loss 0.273020, Max Test Accuracy 0.996200\n","2020-03-23 18:08:56.532153 Epoch 1245, Training Loss 0.355515, Max Test Accuracy 0.996200\n","2020-03-23 18:11:38.149044 Epoch 1260, Training Loss 0.527872, Max Test Accuracy 0.996200\n","2020-03-23 18:14:19.903779 Epoch 1275, Training Loss 0.766988, Max Test Accuracy 0.996200\n","2020-03-23 18:17:01.938655 Epoch 1290, Training Loss 0.120644, Max Test Accuracy 0.996200\n","2020-03-23 18:19:44.191319 Epoch 1305, Training Loss 0.580317, Max Test Accuracy 0.996200\n","2020-03-23 18:22:26.383184 Epoch 1320, Training Loss 0.082843, Max Test Accuracy 0.996200\n","2020-03-23 18:25:08.373265 Epoch 1335, Training Loss 0.007282, Max Test Accuracy 0.996200\n","2020-03-23 18:27:50.128736 Epoch 1350, Training Loss 1.105644, Max Test Accuracy 0.996200\n","2020-03-23 18:30:31.233874 Epoch 1365, Training Loss 0.316593, Max Test Accuracy 0.996200\n","2020-03-23 18:33:12.647735 Epoch 1380, Training Loss 0.127350, Max Test Accuracy 0.996200\n","2020-03-23 18:35:54.049009 Epoch 1395, Training Loss 0.061549, Max Test Accuracy 0.996200\n","2020-03-23 18:38:35.666079 Epoch 1410, Training Loss 0.190335, Max Test Accuracy 0.996200\n","2020-03-23 18:41:16.764425 Epoch 1425, Training Loss 0.026965, Max Test Accuracy 0.996200\n","2020-03-23 18:43:58.324257 Epoch 1440, Training Loss 0.075871, Max Test Accuracy 0.996200\n","2020-03-23 18:46:39.825123 Epoch 1455, Training Loss 0.087840, Max Test Accuracy 0.996200\n","2020-03-23 18:49:22.157976 Epoch 1470, Training Loss 0.041352, Max Test Accuracy 0.996200\n","2020-03-23 18:52:03.808472 Epoch 1485, Training Loss 0.023814, Max Test Accuracy 0.996200\n","2020-03-23 18:54:45.727573 Epoch 1500, Training Loss 0.184916, Max Test Accuracy 0.996200\n","2020-03-23 18:57:27.522558 Epoch 1515, Training Loss 0.085465, Max Test Accuracy 0.996200\n","2020-03-23 19:00:09.553278 Epoch 1530, Training Loss 0.094486, Max Test Accuracy 0.996200\n","2020-03-23 19:02:51.173648 Epoch 1545, Training Loss 0.129041, Max Test Accuracy 0.996200\n","2020-03-23 19:05:33.108139 Epoch 1560, Training Loss 0.851311, Max Test Accuracy 0.996200\n","2020-03-23 19:08:15.312121 Epoch 1575, Training Loss 0.202706, Max Test Accuracy 0.996200\n","2020-03-23 19:10:57.403440 Epoch 1590, Training Loss 0.115248, Max Test Accuracy 0.996200\n","2020-03-23 19:13:39.366851 Epoch 1605, Training Loss 0.148646, Max Test Accuracy 0.996200\n","2020-03-23 19:16:21.295054 Epoch 1620, Training Loss 0.234939, Max Test Accuracy 0.996200\n","2020-03-23 19:19:03.891225 Epoch 1635, Training Loss 0.232936, Max Test Accuracy 0.996200\n","2020-03-23 19:21:45.849041 Epoch 1650, Training Loss 0.081151, Max Test Accuracy 0.996200\n","2020-03-23 19:24:27.165135 Epoch 1665, Training Loss 0.006564, Max Test Accuracy 0.996200\n","2020-03-23 19:27:08.071980 Epoch 1680, Training Loss 0.015403, Max Test Accuracy 0.996200\n","2020-03-23 19:29:49.547744 Epoch 1695, Training Loss 0.034094, Max Test Accuracy 0.996200\n","2020-03-23 19:32:30.555847 Epoch 1710, Training Loss 0.404726, Max Test Accuracy 0.996200\n","2020-03-23 19:35:11.979164 Epoch 1725, Training Loss 0.538166, Max Test Accuracy 0.996200\n","2020-03-23 19:37:53.033070 Epoch 1740, Training Loss 0.393420, Max Test Accuracy 0.996200\n","2020-03-23 19:40:34.251130 Epoch 1755, Training Loss 0.679994, Max Test Accuracy 0.996200\n","2020-03-23 19:43:15.343222 Epoch 1770, Training Loss 0.056507, Max Test Accuracy 0.996200\n","2020-03-23 19:45:56.470427 Epoch 1785, Training Loss 0.022847, Max Test Accuracy 0.996200\n","2020-03-23 19:48:39.255724 Epoch 1800, Training Loss 0.122907, Max Test Accuracy 0.996200\n","2020-03-23 19:51:21.521774 Epoch 1815, Training Loss 0.023921, Max Test Accuracy 0.996200\n","2020-03-23 19:54:02.937718 Epoch 1830, Training Loss 0.155130, Max Test Accuracy 0.996200\n","2020-03-23 19:56:44.310979 Epoch 1845, Training Loss 0.197910, Max Test Accuracy 0.996200\n","2020-03-23 19:59:25.845885 Epoch 1860, Training Loss 0.483179, Max Test Accuracy 0.996200\n","2020-03-23 20:02:08.750033 Epoch 1875, Training Loss 0.248281, Max Test Accuracy 0.996200\n","2020-03-23 20:04:53.043588 Epoch 1890, Training Loss 0.096904, Max Test Accuracy 0.996200\n","2020-03-23 20:07:36.359145 Epoch 1905, Training Loss 0.054050, Max Test Accuracy 0.996200\n","2020-03-23 20:10:23.471351 Epoch 1920, Training Loss 0.011506, Max Test Accuracy 0.996200\n","2020-03-23 20:13:12.500806 Epoch 1935, Training Loss 0.024658, Max Test Accuracy 0.996200\n","2020-03-23 20:16:02.033071 Epoch 1950, Training Loss 0.203740, Max Test Accuracy 0.996200\n","2020-03-23 20:18:54.227023 Epoch 1965, Training Loss 0.033229, Max Test Accuracy 0.996200\n","2020-03-23 20:21:46.562606 Epoch 1980, Training Loss 0.009613, Max Test Accuracy 0.996200\n","2020-03-23 20:24:36.546857 Epoch 1995, Training Loss 0.056963, Max Test Accuracy 0.996200\n","Finished Training\n","Best test accuracy:\n"," [0.9962]\n","2020-03-23 20:25:44.623878 Epoch   1, Training Loss 2011.505694, Max Test Accuracy 0.761600\n","2020-03-23 20:28:22.059761 Epoch  15, Training Loss 21.646962, Max Test Accuracy 0.991300\n","2020-03-23 20:31:11.098799 Epoch  30, Training Loss 10.548463, Max Test Accuracy 0.993100\n","2020-03-23 20:33:59.420888 Epoch  45, Training Loss 7.234038, Max Test Accuracy 0.993900\n","2020-03-23 20:36:46.628933 Epoch  60, Training Loss 5.272897, Max Test Accuracy 0.994500\n","2020-03-23 20:39:32.732668 Epoch  75, Training Loss 3.575422, Max Test Accuracy 0.994600\n","2020-03-23 20:42:18.362035 Epoch  90, Training Loss 4.215169, Max Test Accuracy 0.994700\n","2020-03-23 20:45:02.667983 Epoch 105, Training Loss 3.090282, Max Test Accuracy 0.994700\n","2020-03-23 20:47:49.330839 Epoch 120, Training Loss 2.600014, Max Test Accuracy 0.994700\n","2020-03-23 20:50:34.803888 Epoch 135, Training Loss 1.402412, Max Test Accuracy 0.995200\n","2020-03-23 20:53:18.663101 Epoch 150, Training Loss 1.657940, Max Test Accuracy 0.995200\n","2020-03-23 20:56:02.212467 Epoch 165, Training Loss 0.687879, Max Test Accuracy 0.995200\n","2020-03-23 20:58:45.103089 Epoch 180, Training Loss 1.480616, Max Test Accuracy 0.995200\n","2020-03-23 21:01:26.298705 Epoch 195, Training Loss 1.327868, Max Test Accuracy 0.995200\n","2020-03-23 21:04:06.780377 Epoch 210, Training Loss 1.880497, Max Test Accuracy 0.995200\n","2020-03-23 21:06:47.386223 Epoch 225, Training Loss 1.363163, Max Test Accuracy 0.995200\n","2020-03-23 21:09:28.088751 Epoch 240, Training Loss 1.375487, Max Test Accuracy 0.995200\n","2020-03-23 21:12:08.066972 Epoch 255, Training Loss 0.296939, Max Test Accuracy 0.995200\n","2020-03-23 21:14:48.091169 Epoch 270, Training Loss 1.259540, Max Test Accuracy 0.995200\n","2020-03-23 21:17:28.053752 Epoch 285, Training Loss 1.363812, Max Test Accuracy 0.995200\n","2020-03-23 21:20:09.213598 Epoch 300, Training Loss 0.754577, Max Test Accuracy 0.995200\n","2020-03-23 21:22:49.410496 Epoch 315, Training Loss 0.867823, Max Test Accuracy 0.995200\n","2020-03-23 21:25:29.087913 Epoch 330, Training Loss 1.192865, Max Test Accuracy 0.995200\n","2020-03-23 21:28:09.268006 Epoch 345, Training Loss 0.953629, Max Test Accuracy 0.995200\n","2020-03-23 21:30:49.233338 Epoch 360, Training Loss 0.807703, Max Test Accuracy 0.995200\n","2020-03-23 21:33:29.069053 Epoch 375, Training Loss 0.656996, Max Test Accuracy 0.995200\n","2020-03-23 21:36:08.730160 Epoch 390, Training Loss 0.188271, Max Test Accuracy 0.995200\n","2020-03-23 21:38:48.380951 Epoch 405, Training Loss 0.455747, Max Test Accuracy 0.995200\n","2020-03-23 21:41:27.717231 Epoch 420, Training Loss 0.733312, Max Test Accuracy 0.995200\n","2020-03-23 21:44:07.525876 Epoch 435, Training Loss 1.119027, Max Test Accuracy 0.995200\n","2020-03-23 21:46:47.492895 Epoch 450, Training Loss 0.470519, Max Test Accuracy 0.995200\n","2020-03-23 21:49:27.761584 Epoch 465, Training Loss 0.689647, Max Test Accuracy 0.995200\n","2020-03-23 21:52:07.542166 Epoch 480, Training Loss 0.532624, Max Test Accuracy 0.995200\n","2020-03-23 21:54:47.084073 Epoch 495, Training Loss 0.854128, Max Test Accuracy 0.995200\n","2020-03-23 21:57:26.473619 Epoch 510, Training Loss 0.880424, Max Test Accuracy 0.995200\n","2020-03-23 22:00:05.776446 Epoch 525, Training Loss 0.682500, Max Test Accuracy 0.995400\n","2020-03-23 22:02:44.850952 Epoch 540, Training Loss 0.257210, Max Test Accuracy 0.995400\n","2020-03-23 22:05:24.202710 Epoch 555, Training Loss 1.360716, Max Test Accuracy 0.995400\n","2020-03-23 22:08:03.351636 Epoch 570, Training Loss 0.557209, Max Test Accuracy 0.995400\n","2020-03-23 22:10:42.505133 Epoch 585, Training Loss 0.682492, Max Test Accuracy 0.995400\n","2020-03-23 22:13:21.473235 Epoch 600, Training Loss 0.221204, Max Test Accuracy 0.995800\n","2020-03-23 22:16:00.587516 Epoch 615, Training Loss 0.486533, Max Test Accuracy 0.995800\n","2020-03-23 22:18:39.524006 Epoch 630, Training Loss 0.451487, Max Test Accuracy 0.995800\n","2020-03-23 22:21:19.354426 Epoch 645, Training Loss 0.113991, Max Test Accuracy 0.995800\n","2020-03-23 22:23:58.986973 Epoch 660, Training Loss 0.548434, Max Test Accuracy 0.995800\n","2020-03-23 22:26:38.666473 Epoch 675, Training Loss 0.277984, Max Test Accuracy 0.995800\n","2020-03-23 22:29:17.907552 Epoch 690, Training Loss 0.361741, Max Test Accuracy 0.995800\n","2020-03-23 22:31:57.315968 Epoch 705, Training Loss 1.078229, Max Test Accuracy 0.995900\n","2020-03-23 22:34:36.948097 Epoch 720, Training Loss 0.239441, Max Test Accuracy 0.995900\n","2020-03-23 22:37:16.643813 Epoch 735, Training Loss 0.838818, Max Test Accuracy 0.995900\n","2020-03-23 22:39:56.016535 Epoch 750, Training Loss 0.157254, Max Test Accuracy 0.995900\n","2020-03-23 22:42:35.408092 Epoch 765, Training Loss 0.066174, Max Test Accuracy 0.995900\n","2020-03-23 22:45:14.649323 Epoch 780, Training Loss 0.123081, Max Test Accuracy 0.995900\n","2020-03-23 22:47:53.946792 Epoch 795, Training Loss 0.301653, Max Test Accuracy 0.995900\n","2020-03-23 22:50:33.653195 Epoch 810, Training Loss 0.157109, Max Test Accuracy 0.995900\n","2020-03-23 22:53:14.289101 Epoch 825, Training Loss 0.328415, Max Test Accuracy 0.995900\n","2020-03-23 22:55:54.083395 Epoch 840, Training Loss 0.343080, Max Test Accuracy 0.995900\n","2020-03-23 22:58:33.652941 Epoch 855, Training Loss 0.082866, Max Test Accuracy 0.995900\n","2020-03-23 23:01:13.205240 Epoch 870, Training Loss 0.379002, Max Test Accuracy 0.995900\n","2020-03-23 23:03:52.578808 Epoch 885, Training Loss 0.516054, Max Test Accuracy 0.995900\n","2020-03-23 23:06:31.922969 Epoch 900, Training Loss 0.257684, Max Test Accuracy 0.995900\n","2020-03-23 23:09:11.180173 Epoch 915, Training Loss 0.219726, Max Test Accuracy 0.995900\n","2020-03-23 23:11:50.438414 Epoch 930, Training Loss 0.028891, Max Test Accuracy 0.995900\n","2020-03-23 23:14:29.782449 Epoch 945, Training Loss 0.075303, Max Test Accuracy 0.995900\n","2020-03-23 23:17:09.166590 Epoch 960, Training Loss 0.246586, Max Test Accuracy 0.995900\n","2020-03-23 23:19:48.520702 Epoch 975, Training Loss 0.316686, Max Test Accuracy 0.995900\n","2020-03-23 23:22:29.319039 Epoch 990, Training Loss 0.284498, Max Test Accuracy 0.995900\n","2020-03-23 23:25:09.628131 Epoch 1005, Training Loss 0.178624, Max Test Accuracy 0.995900\n","2020-03-23 23:27:49.772823 Epoch 1020, Training Loss 0.358039, Max Test Accuracy 0.995900\n","2020-03-23 23:30:29.748837 Epoch 1035, Training Loss 0.135659, Max Test Accuracy 0.995900\n","2020-03-23 23:33:09.531318 Epoch 1050, Training Loss 0.076928, Max Test Accuracy 0.995900\n","2020-03-23 23:35:48.848524 Epoch 1065, Training Loss 0.090051, Max Test Accuracy 0.995900\n","2020-03-23 23:38:28.385549 Epoch 1080, Training Loss 0.012955, Max Test Accuracy 0.995900\n","2020-03-23 23:41:08.075846 Epoch 1095, Training Loss 0.220899, Max Test Accuracy 0.995900\n","2020-03-23 23:43:47.869510 Epoch 1110, Training Loss 0.263537, Max Test Accuracy 0.995900\n","2020-03-23 23:46:27.152876 Epoch 1125, Training Loss 0.106807, Max Test Accuracy 0.995900\n","2020-03-23 23:49:06.442591 Epoch 1140, Training Loss 0.040762, Max Test Accuracy 0.995900\n","2020-03-23 23:51:46.143550 Epoch 1155, Training Loss 0.049839, Max Test Accuracy 0.995900\n","2020-03-23 23:54:25.978835 Epoch 1170, Training Loss 0.786500, Max Test Accuracy 0.995900\n","2020-03-23 23:57:05.322179 Epoch 1185, Training Loss 0.216980, Max Test Accuracy 0.995900\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r56aWCTafGuN","colab_type":"text"},"source":["We can use tensorboard to visualize more vividly of out training process."]},{"cell_type":"code","metadata":{"id":"EjOAXO-pfGO4","colab_type":"code","colab":{}},"source":["%tensorboard --logdir runs_Fmax/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEctRbzHV5Xu","colab_type":"text"},"source":[""]}]}